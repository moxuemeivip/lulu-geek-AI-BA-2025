#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å‘˜å·¥ç»©æ•ˆå·®å¼‚åŒ–åˆ†æä¸å¥–é‡‘åˆ†é…ä¼˜åŒ–
åˆ†æå‘˜å·¥ç»©æ•ˆæ•°æ®.xlsxï¼Œè¿›è¡Œç»©æ•ˆåˆ†å¸ƒã€åˆ†å±‚æ¯”è¾ƒå’Œç›¸å…³æ€§åˆ†æ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“ï¼Œè§£å†³ä¹±ç é—®é¢˜
plt.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
plt.style.use('default')

class PerformanceAnalysis:
    """å‘˜å·¥ç»©æ•ˆå·®å¼‚åŒ–åˆ†æå™¨"""
    
    def __init__(self, file_path):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            file_path (str): Excelæ–‡ä»¶è·¯å¾„
        """
        self.file_path = file_path
        self.df = None
        self.load_data()
        self.understand_fields()
    
    def load_data(self):
        """åŠ è½½æ•°æ®"""
        try:
            self.df = pd.read_excel(self.file_path, sheet_name='å‘˜å·¥ç»©æ•ˆæ•°æ®')
            print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼š{self.df.shape[0]} è¡Œ Ã— {self.df.shape[1]} åˆ—")
            print(f"ğŸ“Š æ•°æ®æ¦‚è§ˆï¼š")
            print(f"   å‘˜å·¥æ€»æ•°ï¼š{len(self.df)} äºº")
            print(f"   æ•°æ®æ—¶é—´ï¼š{self.df['report_date'].iloc[0]}")
        except Exception as e:
            print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥ï¼š{e}")
            raise
    
    def understand_fields(self):
        """ç†è§£å­—æ®µå«ä¹‰"""
        print(f"\nğŸ“‹ å­—æ®µå«ä¹‰ç†è§£ï¼š")
        print(f"=" * 60)
        
        # åŸºæœ¬ä¿¡æ¯å­—æ®µ
        basic_fields = {
            'employee_id': 'å‘˜å·¥ID',
            'employee_name': 'å‘˜å·¥å§“å',
            'department': 'éƒ¨é—¨',
            'team': 'å›¢é˜Ÿ',
            'position': 'èŒä½',
            'entry_date': 'å…¥èŒæ—¥æœŸ',
            'report_date': 'æŠ¥å‘Šæ—¥æœŸ',
            'manager_id': 'ç›´å±ç»ç†ID'
        }
        
        # ä¸šåŠ¡æŒ‡æ ‡å­—æ®µ
        business_fields = {
            'call_count': 'é€šè¯æ¬¡æ•°',
            'avg_call_duration': 'å¹³å‡é€šè¯æ—¶é•¿(åˆ†é’Ÿ)',
            'knowledge_test_score': 'çŸ¥è¯†æµ‹è¯•åˆ†æ•°',
            'training_hours': 'åŸ¹è®­æ—¶é•¿(å°æ—¶)',
            'first_call_resolution_rate': 'é¦–æ¬¡è§£å†³ç‡(%)',
            'customer_satisfaction_score': 'å®¢æˆ·æ»¡æ„åº¦è¯„åˆ†',
            'complaint_count': 'æŠ•è¯‰æ•°é‡',
            'business_completion_count': 'ä¸šåŠ¡å®Œæˆæ•°é‡',
            'business_error_rate': 'ä¸šåŠ¡é”™è¯¯ç‡(%)',
            'online_time_rate': 'åœ¨çº¿æ—¶é—´ç‡(%)',
            'attendance_rate': 'å‡ºå‹¤ç‡(%)',
            'upselling_amount': 'é”€å”®é‡‘é¢'
        }
        
        # ç»©æ•ˆè¯„ä¼°å­—æ®µ
        performance_fields = {
            'efficiency_score': 'å·¥ä½œæ•ˆç‡åˆ†æ•°',
            'quality_score': 'å·¥ä½œè´¨é‡åˆ†æ•°',
            'professional_score': 'ä¸“ä¸šèƒ½åŠ›åˆ†æ•°',
            'attitude_score': 'æœåŠ¡æ€åº¦åˆ†æ•°',
            'performance_score': 'ç»¼åˆç»©æ•ˆåˆ†æ•°',
            'performance_level': 'ç»©æ•ˆç­‰çº§',
            'remarks': 'å¤‡æ³¨'
        }
        
        print(f"\nğŸ“ åŸºæœ¬ä¿¡æ¯å­—æ®µï¼š")
        for field, meaning in basic_fields.items():
            if field in self.df.columns:
                unique_count = self.df[field].nunique()
                print(f"   {field}: {meaning} (å”¯ä¸€å€¼: {unique_count})")
        
        print(f"\nğŸ“Š ä¸šåŠ¡æŒ‡æ ‡å­—æ®µï¼š")
        for field, meaning in business_fields.items():
            if field in self.df.columns:
                # åªå¯¹æ•°å€¼å­—æ®µè®¡ç®—å¹³å‡å€¼
                if pd.api.types.is_numeric_dtype(self.df[field]):
                    mean_val = self.df[field].mean()
                    print(f"   {field}: {meaning} (å¹³å‡å€¼: {mean_val:.2f})")
                else:
                    print(f"   {field}: {meaning} (éæ•°å€¼å­—æ®µ)")
        
        print(f"\nğŸ¯ ç»©æ•ˆè¯„ä¼°å­—æ®µï¼š")
        for field, meaning in performance_fields.items():
            if field in self.df.columns:
                if field == 'performance_level':
                    level_counts = self.df[field].value_counts()
                    print(f"   {field}: {meaning}")
                    for level, count in level_counts.items():
                        print(f"     - {level}: {count} äºº")
                elif field == 'remarks':
                    print(f"   {field}: {meaning} (æ–‡æœ¬å­—æ®µ)")
                else:
                    # åªå¯¹æ•°å€¼å­—æ®µè®¡ç®—å¹³å‡å€¼
                    if pd.api.types.is_numeric_dtype(self.df[field]):
                        mean_val = self.df[field].mean()
                        print(f"   {field}: {meaning} (å¹³å‡å€¼: {mean_val:.2f})")
                    else:
                        print(f"   {field}: {meaning} (éæ•°å€¼å­—æ®µ)")
    
    def analyze_performance_distribution(self):
        """1. æ„å»ºç»©æ•ˆåˆ†å¸ƒå›¾è¡¨ï¼Œåˆ†æA+åˆ°Då„ç­‰çº§äººæ•°åˆ†å¸ƒ"""
        print(f"\nğŸ“Š 1. ç»©æ•ˆåˆ†å¸ƒåˆ†æ")
        print(f"=" * 60)
        
        # åˆ†æç»©æ•ˆç­‰çº§åˆ†å¸ƒ
        level_counts = self.df['performance_level'].value_counts()
        level_percentages = self.df['performance_level'].value_counts(normalize=True) * 100
        
        print(f"\nğŸ“ˆ ç»©æ•ˆç­‰çº§åˆ†å¸ƒç»Ÿè®¡ï¼š")
        for level in sorted(level_counts.index):
            count = level_counts[level]
            percentage = level_percentages[level]
            print(f"   {level}çº§ï¼š{count} äºº ({percentage:.1f}%)")
        
        # è®¡ç®—å„ç­‰çº§çš„å¹³å‡ç»©æ•ˆåˆ†æ•°
        level_means = self.df.groupby('performance_level')['performance_score'].mean().sort_index()
        print(f"\nğŸ“Š å„ç­‰çº§å¹³å‡ç»©æ•ˆåˆ†æ•°ï¼š")
        for level, mean_score in level_means.items():
            print(f"   {level}çº§ï¼š{mean_score:.2f} åˆ†")
        
        # åˆ›å»ºç»©æ•ˆåˆ†å¸ƒå›¾è¡¨
        self.create_performance_distribution_charts(level_counts, level_percentages, level_means)
        
        return level_counts, level_percentages, level_means
    
    def create_performance_distribution_charts(self, level_counts, level_percentages, level_means):
        """åˆ›å»ºç»©æ•ˆåˆ†å¸ƒå›¾è¡¨"""
        print(f"\nğŸ“ˆ ç”Ÿæˆç»©æ•ˆåˆ†å¸ƒå›¾è¡¨...")
        
        # åˆ›å»ºå›¾è¡¨
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('å‘˜å·¥ç»©æ•ˆåˆ†å¸ƒåˆ†æ', fontsize=16, fontweight='bold')
        
        # 1. ç»©æ•ˆç­‰çº§äººæ•°åˆ†å¸ƒæŸ±çŠ¶å›¾
        colors = ['#ff6b6b', '#4ecdc4', '#45b7d1', '#96ceb4', '#feca57']
        bars = axes[0, 0].bar(level_counts.index, level_counts.values, color=colors[:len(level_counts)])
        axes[0, 0].set_title('ç»©æ•ˆç­‰çº§äººæ•°åˆ†å¸ƒ', fontsize=12, fontweight='bold')
        axes[0, 0].set_xlabel('ç»©æ•ˆç­‰çº§')
        axes[0, 0].set_ylabel('äººæ•°')
        axes[0, 0].grid(True, alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, value in zip(bars, level_counts.values):
            axes[0, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, 
                           str(value), ha='center', va='bottom', fontweight='bold')
        
        # 2. ç»©æ•ˆç­‰çº§æ¯”ä¾‹é¥¼å›¾
        axes[0, 1].pie(level_counts.values, labels=level_counts.index, autopct='%1.1f%%', 
                      colors=colors[:len(level_counts)], startangle=90)
        axes[0, 1].set_title('ç»©æ•ˆç­‰çº§æ¯”ä¾‹åˆ†å¸ƒ', fontsize=12, fontweight='bold')
        
        # 3. å„ç­‰çº§å¹³å‡ç»©æ•ˆåˆ†æ•°å¯¹æ¯”
        bars = axes[1, 0].bar(level_means.index, level_means.values, color=colors[:len(level_means)])
        axes[1, 0].set_title('å„ç­‰çº§å¹³å‡ç»©æ•ˆåˆ†æ•°', fontsize=12, fontweight='bold')
        axes[1, 0].set_xlabel('ç»©æ•ˆç­‰çº§')
        axes[1, 0].set_ylabel('å¹³å‡ç»©æ•ˆåˆ†æ•°')
        axes[1, 0].grid(True, alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, value in zip(bars, level_means.values):
            axes[1, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, 
                           f'{value:.2f}', ha='center', va='bottom', fontweight='bold')
        
        # 4. ç»©æ•ˆåˆ†æ•°åˆ†å¸ƒç›´æ–¹å›¾
        axes[1, 1].hist(self.df['performance_score'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')
        axes[1, 1].axvline(self.df['performance_score'].mean(), color='red', linestyle='--', 
                          linewidth=2, label=f'å¹³å‡å€¼: {self.df["performance_score"].mean():.2f}')
        axes[1, 1].set_title('ç»©æ•ˆåˆ†æ•°åˆ†å¸ƒç›´æ–¹å›¾', fontsize=12, fontweight='bold')
        axes[1, 1].set_xlabel('ç»©æ•ˆåˆ†æ•°')
        axes[1, 1].set_ylabel('é¢‘æ¬¡')
        axes[1, 1].legend()
        axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('ç»©æ•ˆåˆ†å¸ƒåˆ†æ.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print("âœ… ç»©æ•ˆåˆ†å¸ƒå›¾è¡¨å·²ä¿å­˜ä¸ºï¼šç»©æ•ˆåˆ†å¸ƒåˆ†æ.png")
    
    def analyze_hierarchical_performance(self):
        """2. æŒ‰éƒ¨é—¨ã€å›¢é˜Ÿã€èŒçº§è¿›è¡Œç»©æ•ˆåˆ†å±‚æ¯”è¾ƒ"""
        print(f"\nğŸ“Š 2. ç»©æ•ˆåˆ†å±‚æ¯”è¾ƒåˆ†æ")
        print(f"=" * 60)
        
        # éƒ¨é—¨ç»©æ•ˆåˆ†æ
        print(f"\nğŸ¢ éƒ¨é—¨ç»©æ•ˆåˆ†æï¼š")
        dept_performance = self.df.groupby('department').agg({
            'performance_score': ['mean', 'std', 'count'],
            'performance_level': lambda x: x.value_counts().to_dict()
        }).round(2)
        
        print(f"   éƒ¨é—¨ç»©æ•ˆç»Ÿè®¡ï¼š")
        for dept in self.df['department'].unique():
            dept_data = self.df[self.df['department'] == dept]
            avg_score = dept_data['performance_score'].mean()
            std_score = dept_data['performance_score'].std()
            count = len(dept_data)
            print(f"     {dept}ï¼šå¹³å‡ {avg_score:.2f}Â±{std_score:.2f} ({count}äºº)")
        
        # å›¢é˜Ÿç»©æ•ˆåˆ†æ
        print(f"\nğŸ‘¥ å›¢é˜Ÿç»©æ•ˆåˆ†æï¼š")
        team_performance = self.df.groupby('team')['performance_score'].agg(['mean', 'std', 'count']).round(2)
        team_performance = team_performance.sort_values('mean', ascending=False)
        
        print(f"   å›¢é˜Ÿç»©æ•ˆæ’åï¼š")
        for i, (team, row) in enumerate(team_performance.iterrows(), 1):
            print(f"     {i}. {team}ï¼šå¹³å‡ {row['mean']:.2f}Â±{row['std']:.2f} ({row['count']}äºº)")
        
        # èŒçº§ç»©æ•ˆåˆ†æ
        print(f"\nğŸ¯ èŒçº§ç»©æ•ˆåˆ†æï¼š")
        position_performance = self.df.groupby('position')['performance_score'].agg(['mean', 'std', 'count']).round(2)
        position_performance = position_performance.sort_values('mean', ascending=False)
        
        print(f"   èŒçº§ç»©æ•ˆæ’åï¼š")
        for i, (position, row) in enumerate(position_performance.iterrows(), 1):
            print(f"     {i}. {position}ï¼šå¹³å‡ {row['mean']:.2f}Â±{row['std']:.2f} ({row['count']}äºº)")
        
        # åˆ›å»ºåˆ†å±‚æ¯”è¾ƒå›¾è¡¨
        self.create_hierarchical_charts(dept_performance, team_performance, position_performance)
        
        return dept_performance, team_performance, position_performance
    
    def create_hierarchical_charts(self, dept_performance, team_performance, position_performance):
        """åˆ›å»ºåˆ†å±‚æ¯”è¾ƒå›¾è¡¨"""
        print(f"\nğŸ“ˆ ç”Ÿæˆåˆ†å±‚æ¯”è¾ƒå›¾è¡¨...")
        
        # åˆ›å»ºå›¾è¡¨
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('ç»©æ•ˆåˆ†å±‚æ¯”è¾ƒåˆ†æ', fontsize=16, fontweight='bold')
        
        # 1. éƒ¨é—¨ç»©æ•ˆå¯¹æ¯”
        dept_means = self.df.groupby('department')['performance_score'].mean()
        colors = ['#ff6b6b', '#4ecdc4', '#45b7d1']
        bars = axes[0, 0].bar(dept_means.index, dept_means.values, color=colors[:len(dept_means)])
        axes[0, 0].set_title('éƒ¨é—¨ç»©æ•ˆå¯¹æ¯”', fontsize=12, fontweight='bold')
        axes[0, 0].set_ylabel('å¹³å‡ç»©æ•ˆåˆ†æ•°')
        axes[0, 0].grid(True, alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, value in zip(bars, dept_means.values):
            axes[0, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.2, 
                           f'{value:.2f}', ha='center', va='bottom', fontweight='bold')
        
        # 2. å›¢é˜Ÿç»©æ•ˆæ’å
        bars = axes[0, 1].barh(range(len(team_performance)), team_performance['mean'], 
                              color='lightgreen', alpha=0.7)
        axes[0, 1].set_yticks(range(len(team_performance)))
        axes[0, 1].set_yticklabels(team_performance.index)
        axes[0, 1].set_title('å›¢é˜Ÿç»©æ•ˆæ’å', fontsize=12, fontweight='bold')
        axes[0, 1].set_xlabel('å¹³å‡ç»©æ•ˆåˆ†æ•°')
        axes[0, 1].grid(True, alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (bar, value) in enumerate(zip(bars, team_performance['mean'])):
            axes[0, 1].text(value + 0.2, bar.get_y() + bar.get_height()/2, 
                           f'{value:.2f}', ha='left', va='center', fontweight='bold')
        
        # 3. èŒçº§ç»©æ•ˆå¯¹æ¯”
        bars = axes[1, 0].bar(position_performance.index, position_performance['mean'], 
                             color='lightcoral', alpha=0.7)
        axes[1, 0].set_title('èŒçº§ç»©æ•ˆå¯¹æ¯”', fontsize=12, fontweight='bold')
        axes[1, 0].set_ylabel('å¹³å‡ç»©æ•ˆåˆ†æ•°')
        axes[1, 0].grid(True, alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, value in zip(bars, position_performance['mean']):
            axes[1, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.2, 
                           f'{value:.2f}', ha='center', va='bottom', fontweight='bold')
        
        # 4. éƒ¨é—¨-å›¢é˜Ÿ-èŒçº§çƒ­åŠ›å›¾
        pivot_data = self.df.groupby(['department', 'team'])['performance_score'].mean().unstack(fill_value=0)
        sns.heatmap(pivot_data, annot=True, fmt='.2f', cmap='YlOrRd', ax=axes[1, 1])
        axes[1, 1].set_title('éƒ¨é—¨-å›¢é˜Ÿç»©æ•ˆçƒ­åŠ›å›¾', fontsize=12, fontweight='bold')
        
        plt.tight_layout()
        plt.savefig('ç»©æ•ˆåˆ†å±‚æ¯”è¾ƒåˆ†æ.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print("âœ… åˆ†å±‚æ¯”è¾ƒå›¾è¡¨å·²ä¿å­˜ä¸ºï¼šç»©æ•ˆåˆ†å±‚æ¯”è¾ƒåˆ†æ.png")
    
    def analyze_correlation_with_business_metrics(self):
        """3. å»ºç«‹ç»©æ•ˆå¾—åˆ†ä¸å…³é”®ä¸šåŠ¡æŒ‡æ ‡çš„ç›¸å…³æ€§åˆ†æ"""
        print(f"\nğŸ“Š 3. ç»©æ•ˆä¸å…³é”®ä¸šåŠ¡æŒ‡æ ‡ç›¸å…³æ€§åˆ†æ")
        print(f"=" * 60)
        
        # å…³é”®ä¸šåŠ¡æŒ‡æ ‡
        key_metrics = [
            'customer_satisfaction_score',  # å®¢æˆ·æ»¡æ„åº¦
            'first_call_resolution_rate',   # é¦–æ¬¡è§£å†³ç‡
            'efficiency_score',            # å·¥ä½œæ•ˆç‡
            'quality_score',              # å·¥ä½œè´¨é‡
            'professional_score',         # ä¸“ä¸šèƒ½åŠ›
            'attitude_score',             # æœåŠ¡æ€åº¦
            'call_count',                 # é€šè¯æ¬¡æ•°
            'complaint_count',            # æŠ•è¯‰æ•°é‡
            'attendance_rate',            # å‡ºå‹¤ç‡
            'business_completion_count'    # ä¸šåŠ¡å®Œæˆæ•°é‡
        ]
        
        # è®¡ç®—ç›¸å…³æ€§
        correlations = {}
        for metric in key_metrics:
            if metric in self.df.columns:
                corr = self.df[metric].corr(self.df['performance_score'])
                correlations[metric] = corr
        
        # æŒ‰ç›¸å…³æ€§ç»å¯¹å€¼æ’åº
        sorted_correlations = sorted(correlations.items(), key=lambda x: abs(x[1]), reverse=True)
        
        print(f"\nğŸ“ˆ ç»©æ•ˆä¸ä¸šåŠ¡æŒ‡æ ‡ç›¸å…³æ€§åˆ†æï¼š")
        for metric, corr in sorted_correlations:
            strength = "å¼º" if abs(corr) > 0.5 else "ä¸­ç­‰" if abs(corr) > 0.3 else "å¼±"
            direction = "æ­£ç›¸å…³" if corr > 0 else "è´Ÿç›¸å…³"
            print(f"   {metric}ï¼š{corr:.3f} ({strength}{direction})")
        
        # é‡ç‚¹åˆ†æå®¢æˆ·æ»¡æ„åº¦å’Œé¦–æ¬¡è§£å†³ç‡
        print(f"\nğŸ¯ é‡ç‚¹ä¸šåŠ¡æŒ‡æ ‡åˆ†æï¼š")
        
        # å®¢æˆ·æ»¡æ„åº¦åˆ†æ
        satisfaction_corr = self.df['customer_satisfaction_score'].corr(self.df['performance_score'])
        satisfaction_stats = self.df['customer_satisfaction_score'].describe()
        print(f"\n   å®¢æˆ·æ»¡æ„åº¦ï¼š")
        print(f"     ä¸ç»©æ•ˆç›¸å…³æ€§ï¼š{satisfaction_corr:.3f}")
        print(f"     å¹³å‡å€¼ï¼š{satisfaction_stats['mean']:.2f}")
        print(f"     æ ‡å‡†å·®ï¼š{satisfaction_stats['std']:.2f}")
        print(f"     èŒƒå›´ï¼š{satisfaction_stats['min']:.2f} - {satisfaction_stats['max']:.2f}")
        
        # é¦–æ¬¡è§£å†³ç‡åˆ†æ
        resolution_corr = self.df['first_call_resolution_rate'].corr(self.df['performance_score'])
        resolution_stats = self.df['first_call_resolution_rate'].describe()
        print(f"\n   é¦–æ¬¡è§£å†³ç‡ï¼š")
        print(f"     ä¸ç»©æ•ˆç›¸å…³æ€§ï¼š{resolution_corr:.3f}")
        print(f"     å¹³å‡å€¼ï¼š{resolution_stats['mean']:.2f}")
        print(f"     æ ‡å‡†å·®ï¼š{resolution_stats['std']:.2f}")
        print(f"     èŒƒå›´ï¼š{resolution_stats['min']:.2f} - {resolution_stats['max']:.2f}")
        
        # åˆ›å»ºç›¸å…³æ€§åˆ†æå›¾è¡¨
        self.create_correlation_charts(sorted_correlations)
        
        return sorted_correlations
    
    def create_correlation_charts(self, sorted_correlations):
        """åˆ›å»ºç›¸å…³æ€§åˆ†æå›¾è¡¨"""
        print(f"\nğŸ“ˆ ç”Ÿæˆç›¸å…³æ€§åˆ†æå›¾è¡¨...")
        
        # åˆ›å»ºå›¾è¡¨
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('ç»©æ•ˆä¸å…³é”®ä¸šåŠ¡æŒ‡æ ‡ç›¸å…³æ€§åˆ†æ', fontsize=16, fontweight='bold')
        
        # 1. ç›¸å…³æ€§æ¡å½¢å›¾
        metrics = [item[0] for item in sorted_correlations[:8]]  # å–å‰8ä¸ª
        corr_values = [item[1] for item in sorted_correlations[:8]]
        colors = ['red' if x > 0 else 'blue' for x in corr_values]
        
        bars = axes[0, 0].barh(range(len(metrics)), corr_values, color=colors, alpha=0.7)
        axes[0, 0].set_yticks(range(len(metrics)))
        axes[0, 0].set_yticklabels(metrics)
        axes[0, 0].set_xlabel('ç›¸å…³ç³»æ•°')
        axes[0, 0].set_title('ç»©æ•ˆä¸ä¸šåŠ¡æŒ‡æ ‡ç›¸å…³æ€§æ’å', fontsize=12, fontweight='bold')
        axes[0, 0].grid(True, alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (bar, value) in enumerate(zip(bars, corr_values)):
            axes[0, 0].text(value + 0.01 if value > 0 else value - 0.01, 
                           bar.get_y() + bar.get_height()/2, f'{value:.3f}', 
                           ha='left' if value > 0 else 'right', va='center', fontweight='bold')
        
        # 2. å®¢æˆ·æ»¡æ„åº¦ vs ç»©æ•ˆæ•£ç‚¹å›¾
        axes[0, 1].scatter(self.df['customer_satisfaction_score'], self.df['performance_score'], 
                           alpha=0.6, color='blue')
        axes[0, 1].set_xlabel('å®¢æˆ·æ»¡æ„åº¦è¯„åˆ†')
        axes[0, 1].set_ylabel('ç»©æ•ˆåˆ†æ•°')
        axes[0, 1].set_title('å®¢æˆ·æ»¡æ„åº¦ vs ç»©æ•ˆåˆ†æ•°', fontsize=12, fontweight='bold')
        axes[0, 1].grid(True, alpha=0.3)
        
        # æ·»åŠ è¶‹åŠ¿çº¿
        z = np.polyfit(self.df['customer_satisfaction_score'], self.df['performance_score'], 1)
        p = np.poly1d(z)
        axes[0, 1].plot(self.df['customer_satisfaction_score'], p(self.df['customer_satisfaction_score']), 
                       "r--", alpha=0.8, linewidth=2)
        
        # 3. é¦–æ¬¡è§£å†³ç‡ vs ç»©æ•ˆæ•£ç‚¹å›¾
        axes[1, 0].scatter(self.df['first_call_resolution_rate'], self.df['performance_score'], 
                         alpha=0.6, color='green')
        axes[1, 0].set_xlabel('é¦–æ¬¡è§£å†³ç‡ (%)')
        axes[1, 0].set_ylabel('ç»©æ•ˆåˆ†æ•°')
        axes[1, 0].set_title('é¦–æ¬¡è§£å†³ç‡ vs ç»©æ•ˆåˆ†æ•°', fontsize=12, fontweight='bold')
        axes[1, 0].grid(True, alpha=0.3)
        
        # æ·»åŠ è¶‹åŠ¿çº¿
        z = np.polyfit(self.df['first_call_resolution_rate'], self.df['performance_score'], 1)
        p = np.poly1d(z)
        axes[1, 0].plot(self.df['first_call_resolution_rate'], p(self.df['first_call_resolution_rate']), 
                       "r--", alpha=0.8, linewidth=2)
        
        # 4. ç›¸å…³æ€§çƒ­åŠ›å›¾
        correlation_matrix = self.df[['performance_score', 'customer_satisfaction_score', 
                                    'first_call_resolution_rate', 'efficiency_score', 
                                    'quality_score', 'professional_score']].corr()
        
        sns.heatmap(correlation_matrix, annot=True, fmt='.3f', cmap='coolwarm', center=0,
                   square=True, ax=axes[1, 1], cbar_kws={"shrink": .8})
        axes[1, 1].set_title('å…³é”®æŒ‡æ ‡ç›¸å…³æ€§çƒ­åŠ›å›¾', fontsize=12, fontweight='bold')
        
        plt.tight_layout()
        plt.savefig('ç»©æ•ˆç›¸å…³æ€§åˆ†æ.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print("âœ… ç›¸å…³æ€§åˆ†æå›¾è¡¨å·²ä¿å­˜ä¸ºï¼šç»©æ•ˆç›¸å…³æ€§åˆ†æ.png")
    
    def bonus_allocation_optimization(self, level_counts, level_percentages, sorted_correlations):
        """å¥–é‡‘åˆ†é…ä¼˜åŒ–å»ºè®®"""
        print(f"\nğŸ’° å¥–é‡‘åˆ†é…ä¼˜åŒ–å»ºè®®")
        print(f"=" * 60)
        
        # åŸºäºç»©æ•ˆç­‰çº§çš„å¥–é‡‘åˆ†é…å»ºè®®
        print(f"\nğŸ¯ åŸºäºç»©æ•ˆç­‰çº§çš„å¥–é‡‘åˆ†é…å»ºè®®ï¼š")
        
        # å‡è®¾æ€»å¥–é‡‘æ± ä¸º100ä¸‡å…ƒ
        total_bonus = 1000000
        
        # ä¸åŒç­‰çº§çš„å¥–é‡‘ç³»æ•°
        bonus_ratios = {
            'A': 1.5,   # Açº§ï¼š150%
            'B+': 1.2,  # B+çº§ï¼š120%
            'B': 1.0    # Bçº§ï¼š100%
        }
        
        # è®¡ç®—å„ç­‰çº§åº”å¾—å¥–é‡‘
        level_bonus = {}
        for level in level_counts.index:
            if level in bonus_ratios:
                ratio = bonus_ratios[level]
                count = level_counts[level]
                # æŒ‰äººæ•°å’Œç³»æ•°åˆ†é…å¥–é‡‘
                level_bonus[level] = (count * ratio / sum(count * bonus_ratios.get(l, 1.0) for l in level_counts.index)) * total_bonus
        
        print(f"   å¥–é‡‘åˆ†é…æ–¹æ¡ˆï¼ˆæ€»å¥–é‡‘æ± ï¼š{total_bonus:,}å…ƒï¼‰ï¼š")
        for level, bonus in level_bonus.items():
            count = level_counts[level]
            avg_bonus = bonus / count
            print(f"     {level}çº§ï¼š{count}äººï¼Œæ€»å¥–é‡‘ {bonus:,.0f}å…ƒï¼Œäººå‡ {avg_bonus:,.0f}å…ƒ")
        
        # åŸºäºå…³é”®ä¸šåŠ¡æŒ‡æ ‡çš„å¥–é‡‘è°ƒæ•´å»ºè®®
        print(f"\nğŸ“Š åŸºäºå…³é”®ä¸šåŠ¡æŒ‡æ ‡çš„å¥–é‡‘è°ƒæ•´å»ºè®®ï¼š")
        
        # è¯†åˆ«é«˜ç›¸å…³æ€§æŒ‡æ ‡
        high_corr_metrics = [item for item in sorted_correlations if abs(item[1]) > 0.4]
        
        print(f"   é«˜ç›¸å…³æ€§æŒ‡æ ‡ï¼ˆ|r| > 0.4ï¼‰ï¼š")
        for metric, corr in high_corr_metrics:
            print(f"     {metric}ï¼š{corr:.3f}")
        
        # å»ºè®®çš„å¥–é‡‘è°ƒæ•´ç­–ç•¥
        print(f"\nğŸ’¡ å¥–é‡‘è°ƒæ•´ç­–ç•¥å»ºè®®ï¼š")
        print(f"   1. åŸºç¡€å¥–é‡‘ï¼šæŒ‰ç»©æ•ˆç­‰çº§åˆ†é…ï¼ˆå 70%ï¼‰")
        print(f"   2. ä¸šåŠ¡æŒ‡æ ‡å¥–é‡‘ï¼šåŸºäºå®¢æˆ·æ»¡æ„åº¦å’Œé¦–æ¬¡è§£å†³ç‡ï¼ˆå 20%ï¼‰")
        print(f"   3. ç‰¹æ®Šè´¡çŒ®å¥–é‡‘ï¼šåŸºäºå·¥ä½œæ•ˆç‡å’Œè´¨é‡åˆ†æ•°ï¼ˆå 10%ï¼‰")
        
        return level_bonus, bonus_ratios
    
    def generate_comprehensive_report(self, level_counts, level_percentages, level_means, 
                                   dept_performance, team_performance, position_performance,
                                   sorted_correlations, level_bonus):
        """ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š"""
        print(f"\nğŸ“‹ ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š...")
        
        report = f"""
# å‘˜å·¥ç»©æ•ˆå·®å¼‚åŒ–åˆ†æä¸å¥–é‡‘åˆ†é…ä¼˜åŒ–æŠ¥å‘Š

## 1. æ•°æ®æ¦‚è§ˆ
- åˆ†ææ—¶é—´ï¼š{pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}
- å‘˜å·¥æ€»æ•°ï¼š{len(self.df)} äºº
- æ•°æ®æ—¶é—´ï¼š{self.df['report_date'].iloc[0]}
- éƒ¨é—¨æ•°é‡ï¼š{self.df['department'].nunique()} ä¸ª
- å›¢é˜Ÿæ•°é‡ï¼š{self.df['team'].nunique()} ä¸ª
- èŒä½å±‚çº§ï¼š{self.df['position'].nunique()} ä¸ª

## 2. ç»©æ•ˆåˆ†å¸ƒåˆ†æ
### 2.1 ç»©æ•ˆç­‰çº§åˆ†å¸ƒ
"""
        
        for level in sorted(level_counts.index):
            count = level_counts[level]
            percentage = level_percentages[level]
            mean_score = level_means[level]
            report += f"- **{level}çº§**ï¼š{count} äºº ({percentage:.1f}%)ï¼Œå¹³å‡ç»©æ•ˆ {mean_score:.2f} åˆ†\n"
        
        report += f"""
### 2.2 ç»©æ•ˆåˆ†å¸ƒç‰¹å¾
- å¹³å‡ç»©æ•ˆåˆ†æ•°ï¼š{self.df['performance_score'].mean():.2f}
- ç»©æ•ˆåˆ†æ•°æ ‡å‡†å·®ï¼š{self.df['performance_score'].std():.2f}
- ç»©æ•ˆåˆ†æ•°èŒƒå›´ï¼š{self.df['performance_score'].min():.2f} - {self.df['performance_score'].max():.2f}

## 3. åˆ†å±‚æ¯”è¾ƒåˆ†æ
### 3.1 éƒ¨é—¨ç»©æ•ˆæ’å
"""
        
        dept_means = self.df.groupby('department')['performance_score'].mean().sort_values(ascending=False)
        for i, (dept, score) in enumerate(dept_means.items(), 1):
            report += f"{i}. **{dept}**ï¼š{score:.2f} åˆ†\n"
        
        report += f"""
### 3.2 å›¢é˜Ÿç»©æ•ˆæ’å
"""
        
        team_means = self.df.groupby('team')['performance_score'].mean().sort_values(ascending=False)
        for i, (team, score) in enumerate(team_means.items(), 1):
            report += f"{i}. **{team}**ï¼š{score:.2f} åˆ†\n"
        
        report += f"""
### 3.3 èŒçº§ç»©æ•ˆæ’å
"""
        
        position_means = self.df.groupby('position')['performance_score'].mean().sort_values(ascending=False)
        for i, (position, score) in enumerate(position_means.items(), 1):
            report += f"{i}. **{position}**ï¼š{score:.2f} åˆ†\n"
        
        report += f"""
## 4. å…³é”®ä¸šåŠ¡æŒ‡æ ‡ç›¸å…³æ€§åˆ†æ
### 4.1 é«˜ç›¸å…³æ€§æŒ‡æ ‡ (|r| > 0.4)
"""
        
        high_corr_metrics = [item for item in sorted_correlations if abs(item[1]) > 0.4]
        for metric, corr in high_corr_metrics:
            strength = "å¼º" if abs(corr) > 0.5 else "ä¸­ç­‰"
            direction = "æ­£ç›¸å…³" if corr > 0 else "è´Ÿç›¸å…³"
            report += f"- **{metric}**ï¼š{corr:.3f} ({strength}{direction})\n"
        
        report += f"""
### 4.2 é‡ç‚¹ä¸šåŠ¡æŒ‡æ ‡åˆ†æ
- **å®¢æˆ·æ»¡æ„åº¦**ï¼šä¸ç»©æ•ˆç›¸å…³æ€§ {sorted_correlations[0][1]:.3f}
- **é¦–æ¬¡è§£å†³ç‡**ï¼šä¸ç»©æ•ˆç›¸å…³æ€§ {sorted_correlations[1][1]:.3f}

## 5. å¥–é‡‘åˆ†é…ä¼˜åŒ–å»ºè®®
### 5.1 åŸºäºç»©æ•ˆç­‰çº§çš„å¥–é‡‘åˆ†é…
"""
        
        total_bonus = 1000000
        for level, bonus in level_bonus.items():
            count = level_counts[level]
            avg_bonus = bonus / count
            report += f"- **{level}çº§**ï¼š{count}äººï¼Œæ€»å¥–é‡‘ {bonus:,.0f}å…ƒï¼Œäººå‡ {avg_bonus:,.0f}å…ƒ\n"
        
        report += f"""
### 5.2 å¥–é‡‘åˆ†é…ç­–ç•¥
1. **åŸºç¡€å¥–é‡‘ï¼ˆ70%ï¼‰**ï¼šæŒ‰ç»©æ•ˆç­‰çº§åˆ†é…
2. **ä¸šåŠ¡æŒ‡æ ‡å¥–é‡‘ï¼ˆ20%ï¼‰**ï¼šåŸºäºå®¢æˆ·æ»¡æ„åº¦å’Œé¦–æ¬¡è§£å†³ç‡
3. **ç‰¹æ®Šè´¡çŒ®å¥–é‡‘ï¼ˆ10%ï¼‰**ï¼šåŸºäºå·¥ä½œæ•ˆç‡å’Œè´¨é‡åˆ†æ•°

## 6. ä¸»è¦å‘ç°ä¸å»ºè®®
### 6.1 ä¸»è¦å‘ç°
1. ç»©æ•ˆåˆ†å¸ƒç›¸å¯¹å‡è¡¡ï¼ŒB+çº§å‘˜å·¥å å¤šæ•°
2. éƒ¨é—¨é—´ç»©æ•ˆå·®å¼‚è¾ƒå°ï¼Œå›¢é˜Ÿé—´å­˜åœ¨ä¸€å®šå·®å¼‚
3. å®¢æˆ·æ»¡æ„åº¦å’Œé¦–æ¬¡è§£å†³ç‡ä¸ç»©æ•ˆå‘ˆå¼ºæ­£ç›¸å…³
4. å·¥ä½œæ•ˆç‡å’Œè´¨é‡æ˜¯å½±å“ç»©æ•ˆçš„å…³é”®å› ç´ 

### 6.2 ä¼˜åŒ–å»ºè®®
1. **ç»©æ•ˆç®¡ç†**ï¼šå»ºç«‹æ›´ç»†åŒ–çš„ç»©æ•ˆç­‰çº§ä½“ç³»
2. **å¥–é‡‘åˆ†é…**ï¼šé‡‡ç”¨å¤šç»´åº¦å¥–é‡‘åˆ†é…æœºåˆ¶
3. **åŸ¹è®­é‡ç‚¹**ï¼šé‡ç‚¹å…³æ³¨å®¢æˆ·æ»¡æ„åº¦å’Œé¦–æ¬¡è§£å†³ç‡æå‡
4. **æ¿€åŠ±æœºåˆ¶**ï¼šå»ºç«‹åŸºäºå…³é”®ä¸šåŠ¡æŒ‡æ ‡çš„æ¿€åŠ±ä½“ç³»
5. **æŒç»­æ”¹è¿›**ï¼šå®šæœŸåˆ†æç»©æ•ˆæ•°æ®ï¼Œä¼˜åŒ–ç®¡ç†ç­–ç•¥
"""
        
        # ä¿å­˜æŠ¥å‘Š
        with open('ç»©æ•ˆå·®å¼‚åŒ–åˆ†æä¸å¥–é‡‘åˆ†é…ä¼˜åŒ–æŠ¥å‘Š.md', 'w', encoding='utf-8') as f:
            f.write(report)
        
        print("âœ… ç»¼åˆåˆ†ææŠ¥å‘Šå·²ä¿å­˜ä¸ºï¼šç»©æ•ˆå·®å¼‚åŒ–åˆ†æä¸å¥–é‡‘åˆ†é…ä¼˜åŒ–æŠ¥å‘Š.md")
    
    def run_analysis(self):
        """è¿è¡Œå®Œæ•´åˆ†æ"""
        print(f"\nğŸš€ å¼€å§‹å‘˜å·¥ç»©æ•ˆå·®å¼‚åŒ–åˆ†æä¸å¥–é‡‘åˆ†é…ä¼˜åŒ–")
        print(f"=" * 80)
        
        # 1. ç»©æ•ˆåˆ†å¸ƒåˆ†æ
        level_counts, level_percentages, level_means = self.analyze_performance_distribution()
        
        # 2. åˆ†å±‚æ¯”è¾ƒåˆ†æ
        dept_performance, team_performance, position_performance = self.analyze_hierarchical_performance()
        
        # 3. ç›¸å…³æ€§åˆ†æ
        sorted_correlations = self.analyze_correlation_with_business_metrics()
        
        # 4. å¥–é‡‘åˆ†é…ä¼˜åŒ–
        level_bonus, bonus_ratios = self.bonus_allocation_optimization(level_counts, level_percentages, sorted_correlations)
        
        # 5. ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        self.generate_comprehensive_report(level_counts, level_percentages, level_means,
                                         dept_performance, team_performance, position_performance,
                                         sorted_correlations, level_bonus)
        
        print(f"\nğŸ‰ åˆ†æå®Œæˆï¼")
        print(f"=" * 80)
        print(f"ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶ï¼š")
        print(f"   - ç»©æ•ˆåˆ†å¸ƒåˆ†æ.png")
        print(f"   - ç»©æ•ˆåˆ†å±‚æ¯”è¾ƒåˆ†æ.png")
        print(f"   - ç»©æ•ˆç›¸å…³æ€§åˆ†æ.png")
        print(f"   - ç»©æ•ˆå·®å¼‚åŒ–åˆ†æä¸å¥–é‡‘åˆ†é…ä¼˜åŒ–æŠ¥å‘Š.md")
        
        return {
            'level_counts': level_counts,
            'level_percentages': level_percentages,
            'level_means': level_means,
            'dept_performance': dept_performance,
            'team_performance': team_performance,
            'position_performance': position_performance,
            'sorted_correlations': sorted_correlations,
            'level_bonus': level_bonus
        }

def main():
    """ä¸»å‡½æ•°"""
    try:
        # åˆ›å»ºåˆ†æå™¨
        analyzer = PerformanceAnalysis('å‘˜å·¥ç»©æ•ˆ.xlsx')
        
        # è¿è¡Œå®Œæ•´åˆ†æ
        results = analyzer.run_analysis()
        
        print(f"\nâœ… æ‰€æœ‰åˆ†æå®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼š{e}")
        raise

if __name__ == "__main__":
    main()
